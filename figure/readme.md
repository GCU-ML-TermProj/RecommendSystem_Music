### 사용한 데이터셋
- train dataset : Official Million Song Dataset 중 2,000,000건 (노래는 10,000개)의 데이터
- test dataset : Million Song Dataset Challenge(https://www.kaggle.com/competitions/msdchallenge/code) 에서 제공하는 테스트 데이터셋 (실제 precision 나온거랑 다른 사람들 성능 비교해보려고 일부러 이 데이터셋을 사용)

### 실험 환경
- Runpod
- 사용라이브러리 : os, sys, subprocess, warnings, numpy, pandas, time, matplotlib, sklearn, scipy, math, seaborn, surprise

### 사용한 전처리 방법
| 처리 범주 | 사용된 방법 | 목적 및 내용 |
| :--- | :--- | :--- |
| **1. 데이터 정제** | `groupby().max()` | `song_id` 기준 중복 메타데이터 제거 |
| | `pd.merge` | 청취 기록(txt)과 노래 메타데이터(csv) 병합 |
| | `rename`, `del` | 컬럼 이름 변경 (`play_count` -> `listen_count`) 및 불필요한 컬럼 삭제 |
| | 0년인 데이터 삭제, 200이 넘는 청취횟수는 삭제 | 결측치 삭제, 극단치 삭제 |
| **2. 피처 엔지니어링** | 비율 계산 | `fractional_play_count` (총 청취 수 대비 개별 곡 청취 비중) 생성 |
| | 로그 변환 (`np.log1p`) | 청취 횟수(listen_count)의 롱테일 분포를 정규화. 왜 그래야 했냐면, listen_count(청취 횟수) 데이터는 1~10회에 대부분이 몰려있고 2,213회 같은 극단적인 이상치가 존재해 매우 편향되어 있기 때문에 로그 변환을 사용했습니다. 로그는 이 거대한 범위를 압축하여 안정화시키고, 1번과 10번의 청취 차이(선호도)를 1000번과 1010번의 차이보다 더 의미 있게 반영하여 모델이 정확하게 학습하도록 돕습니다. |
| | 스케일링 (Scaling) | 로그 변환된 값을 1~5점 척도의 `rating`으로 변환 (Surprise용) |
| **3. 데이터 샘플링/필터링** | 서브셋 생성 (Filtering) | 계산 효율을 위해 인기 상위 5,000곡 (`song_subset`) / 상위 1,500명/곡으로 데이터 축소 |
| | 테스트셋 구축 | `sample(frac=...)` 및 `pd.concat`을 사용하여 평가(eval)셋과 훈련(train)셋을 조합한 테스트 데이터 생성 |
| **4. 구조 변환** | 인덱싱 (Label Encoding) | `user`, `song` ID(문자열)를 정수 인덱스(`us_index_value`, `so_index_value`)로 변환 |
| | 희소 행렬 변환 | `scipy.sparse.coo_matrix`를 사용해 SVD 연산을 위한 희소 행렬 생성 |
| | 라이브러리 포맷 변환 | `surprise.Reader` 및 `Dataset`을 사용해 DataFrame을 Surprise 전용 데이터셋으로 변환 |

### 실험의 순서
| 모델 (Model) | 동작 방식 (스크립트 기준) | 장점 | 단점 |
| :--- | :--- | :--- | :--- |
| **1. 인기도 기반** | `groupby`로 아이템(노래)을 묶고, 고유 사용자 수(`count`)를 'score'로 정의. 이 점수가 높은 순서(Top-N)로 모든 사용자에게 동일하게 추천. | <li>계산이 매우 빠르고 구현이 가장 간단함.</li><li>데이터가 부족한 초기 사용자(Cold Start)나 비로그인 사용자에게 적합.</li><li>대중적으로 검증된(안전한) 아이템을 추천. | <li>**개인화가 전혀 불가능** (모든 사용자에게 동일한 추천).</li><li>인기 없는 '롱테일' 아이템을 추천할 기회가 없음 (다양성 부족).</li><li>사용자의 개별 취향을 무시함. |
| **2. 아이템 유사도** | 사용자가 들은 아이템(N개)과 전체 아이템(M개) 간의 **Jaccard 유사도** (공청자 수 교집합 / 합집합)를 계산. N x M 크기의 공동 발생 행렬(co-occurrence matrix)을 생성하고, 유사도 점수를 합산하여 개인화 추천. | <li>개인화된 추천이 가능.</li><li>"이 노래를 들은 사람이 저 노래도 들음"이라는 직관적인 추천 근거를 가짐.</li><li>사용자의 과거 이력에 기반하여 관련성 높은 아이템을 추천. | <li>아이템이 많아지면 **계산 비용(N x M)이 매우 높음** (스크립트에서도 5천 개로 축소함).</li><li>새로운 아이템이나 신규 사용자에 대한 추천이 어려움 (Cold Start).</li><li>추천이 '필터 버블'에 갇히기 쉬움 (들은 것과 비슷한 것만 추천). |
| **3. SVD (`scipy`)** | `fractional_play_count`(청취 비중)를 평점으로 사용. 이를 **희소 행렬**로 변환 후, `scipy.svds`로 K=50개의 잠재 요인(U, S, Vt)으로 분해. U와 Vt를 다시 곱하여 비어있는 평점을 예측하고 추천. | <li>대규모 희소 행렬(Sparse Matrix)을 효율적으로 처리.</li><li>'잠재 요인(Latent Factor)'을 통해 사용자와 아이템의 숨겨진 특징(취향, 장르 등)을 학습.</li><li>아이템 유사도 모델보다 더 의외의(Serendipity) 추천이 가능. | <li>추천 결과를 해석하기 어려움 (잠재 요인이 무엇을 의미하는지 모름).</li><li>`scipy.svds`는 단순 분해 함수일 뿐, 추천 시스템에 최적화된 알고리즘(예: 편향 고려)이 아님.</li><li>`fractional_play_count`라는 평점 정의가 다소 인위적임. |
| **4. KNN (`surprise`)** | `listen_count`를 **로그 변환 + 1~5점 스케일링**한 `rating` 사용. 아이템 기반 **코사인(Cosine) 유사도**를 계산. `KNNWithMeans`를 사용하여 아이템별 평균 평점(편향)을 보정한 예측 수행. | <li>`surprise` 라이브러리를 사용해 구현이 간편함.</li><li>`WithMeans`를 사용해 아이템별 인기도 편향을 보정하여 정확도를 높임.</li><li>추천 근거가 비교적 명확함 (유사한 아이템 X, Y 기반). | <li>SVD 계열 모델보다 성능(RMSE)이 낮았음.</li><li>데이터가 많아질수록 유사도 행렬이 거대해져 확장성이 떨어짐.</li><li>아이템 유사도 모델과 마찬가지로 Cold Start 문제에 약함. |
| **5. SVD++ (`surprise`)** | `rating` 사용. 기본 SVD 모델(잠재 요인, 편향)에 더해, 사용자가 청취한 **모든 이력(암시적 피드백)**까지 사용자 요인을 정의하는 데 추가로 활용. | <li>**스크립트 내에서 가장 성능(RMSE)이 우수했음.**</li><li>명시적 평점(rating)과 암시적 이력(청취 사실)을 **모두 사용**하여 사용자를 더 정확하게 모델링함.</li><li>추천 시스템에 최적화된 고급 행렬 분해 알고리즘. | <li>모델이 복잡하여 다른 모델들보다 학습 시간이 오래 걸림.</li><li>모델 3(SVD)와 마찬가지로 잠재 요인을 직관적으로 해석하기 어려움.</li> |

### 각 figure 간단한 정리

| 파일이름 | 해석 및 의미 |
| :--- | :--- |
| **(1) 원본 노래 메타데이터\_head 출력.png** | **(데이터 로드 1)** `song_data.csv` (노래 정보) 파일을 로드한 초기 상태입니다. `song_id`에 중복이 있음을 보여주며, 이는 데이터 정제(전처리)의 필요성을 시사합니다. |
| **(2) 사용자 청취 기록\_head 출력.png** | **(데이터 로드 2)** `10000.txt` (사용자 청취 기록) 파일을 로드한 상태입니다. 총 200만 건의 상호작용(interaction) 기록은 추천 모델을 학습시키기에 충분한 규모임을 알 수 있습니다. |
| **(3) song\_id 기준 중복 제거한 후\_head 출력.png** | **(데이터 전처리)** (1)번의 메타데이터에서 `song_id` 중복을 제거한, 정제된 데이터입니다. `song_id`를 고유 키(primary key)로 사용하기 위한 필수적인 전처리 단계입니다. |
| **(4) 청취 기록과\_메타데이터 병합.png** | **(데이터 전처리)** (2)번 청취 기록과 (3)번 노래 정보를 합친(merge) 메인 데이터프레임입니다. 이 병합된 데이터는 사용자-아이템 상호작용과 아이템의 속성(특징)을 모두 포함하는 분석의 기반이 됩니다. |
| **(5) 한 노래를 무려 200회 이상 들은 청취자의\_기본 통계 요약.png** | **(EDA 1)** 한 노래를 200회 이상 들은 '극단적' 청취 기록(최대 2,213회)의 통계입니다. 이러한 아웃라이어(outlier) 데이터는 모델의 성능을 왜곡시킬 수 있어, 정규화나 필터링 대상이 될 수 있습니다. |
| **(6) 가장 많이 재생 1위\_2위\_데이터.png** | **(EDA 2)** (5)번의 '극단적 청취자' 1, 2위가 들은 노래의 상세 정보입니다. (Gorillaz - Starshine 등). 이 사용자들은 '봇'이나 오류 데이터가 아닌, 특정 곡에 대한 '광팬'일 가능성을 보여줍니다. |
| **(7) top20 가장 많이 재생된 곡.jpg** | **(EDA 3)** '총 재생 횟수' 기준 가장 인기 있는 노래 Top 20 시각화입니다. (You're The One이 1위). 이는 인기도 기반 추천 모델의 가장 기본적인 추천 근거가 됩니다. |
| **(8) top20 가장 많이 재생된 앨범.jpg** | **(EDA 4)** '총 재생 횟수' 기준 가장 인기 있는 앨범(릴리스) Top 20 시각화입니다. 개별 곡뿐만 아니라 앨범 단위의 청취 경향성도 존재함을 보여줍니다. |
| **(9) top20 가장 많이 재생된 가수.jpg** | **(EDA 5)** '총 재생 횟수' 기준 가장 인기 있는 아티스트 Top 20 시각화입니다. (Coldplay가 1위). 특정 아티스트에 대한 팬덤이 청취 수에 큰 영향을 미침을 알 수 있습니다. |
| **(10) 가장 많이 재생된 연도.jpg** | **(EDA 6)** 발매 연도별 '총 재생 횟수' 순위입니다. (0년(정보 없음) 제외, 2009년이 1위). '0' 값이 압도적으로 많은 것은 메타데이터에 결측치가 많다는 것을 의미합니다. |
| **(11) 청취횟수분포.png** | **(EDA 7)** '한 곡이 몇 번 재생되었나'의 분포 (로그 스케일)입니다. **대부분의 곡이 10회 미만 재생**되었으며, 이는 데이터가 '희소(sparse)'하고 '롱테일(long-tail)' 형태임을 명확히 보여줍니다. |
| **(12) 사용자활동분포.png** | **(EDA 8)** '한 사용자가 몇 곡을 들었나'의 분포 (로그 스케일)입니다. **대부분의 사용자가 100곡 미만**을 들었으며, 소수의 '헤비 유저'가 전체 청취의 상당 부분을 차지할 수 있습니다. |
| **(13) 노래별인기분포.png** | **(EDA 9)** '한 곡을 몇 명이 들었나'의 분포 (로그 스케일)입니다. **대부분의 노래가 100명 미만의 사용자**에게만 알려졌으며, '콜드 스타트' 문제의 심각성을 보여줍니다. |
| **(14) 데이터셋에가장많은고유곡가진아티스트들.png** | **(EDA 10)** '총 재생 수'가 아닌, **'고유한 곡의 수'**가 많은 아티스트 Top 20입니다. (The Black Keys가 1위). 이는 아티스트의 인기도와 카탈로그의 다양성이 반드시 비례하지는 않음을 보여줍니다. |
| **(15) 발매연도별청취횟수.png** | **(EDA 11)** 발매 연도에 따른 청취 횟수 꺾은선 그래프입니다. **사용자들이 주로 최신(2000년대) 노래를 소비**하며, 2008-2009년에 정점을 찍는 트렌드를 보여줍니다. |
| **(16) 연도별로얼마나청취를기록했는가.png** | **(EDA 12)** 인기 아티스트(Y축)의 음악이 **몇 년도(X축)에 가장 많이 소비되었는지** 보여주는 히트맵입니다. (예: Kings Of Leon은 2008-09년에 집중). 아티스트의 활동 시기와 음악 소비 시기가 밀접하게 연관됨을 시각화합니다. |
| **(17) 인기도기반모델\_가장인기있는노래top15.png** | **(모델 1: 인기도) 결과 (곡)**: '재생 횟수'가 아닌 **'고유 청취자 수'**를 기준으로 한 Top 15 노래입니다. (Sehr kosmisch가 1위). 총 재생 횟수 기준((7)번)과 순위가 다른 것은, 한 명의 광팬보다 다수의 사용자가 들은 것을 더 높게 평가하기 때문입니다. |
| **(18) 인기도기반모델\_가장인기있는아티스트top10.png** | **(모델 1: 인기도) 결과 (아티스트)**: '고유 청취자 수' 기준 Top 10 아티스트입니다. (Coldplay가 1위). 이는 (9)번의 총 재생 횟수 기준과 상위권이 거의 일치하며, Coldplay의 강력한 팬덤을 재확인시켜 줍니다. |
| **(19) 아이템기반모델\_상위5000개중head.png** | **(모델 2: 아이템 유사도) 준비**: 계산량을 줄이기 위해, 가장 인기 있는 5,000곡으로 **데이터를 축소(sub-set)**한 결과입니다. 이 5,000곡이 전체 청취의 81.88%를 차지한다는 것은, 소수의 인기곡에 청취가 집중되어 있음을 의미합니다. |
| **(20) 아이템기반모델\_b80344d유저에게상위10개노래추천.png** | **(모델 2: 아이템 유사도) 결과**: 특정 사용자(`b80344d...`)에게 **개인화된 노래 Top 10을 추천**한 표입니다. 'score'는 해당 사용자가 들은 노래들과의 평균 유사도(co-occurence) 점수입니다. |
| **(21) 아이템기반모델\_b80344d유저에게상위10개노래추천시각화.png** | **(모델 2: 아이템 유사도) 시각화**: (20)번의 추천 결과를 막대그래프로 시각화한 것입니다. 점수 차이가 크지 않아, 추천 목록 내 노래들의 우선순위가 비등함을 보여줍니다. |
| **(22) 아이템기반모델\_b80344d유저가들은노래와추천노래의simmatrix.png** | **(모델 2: 아이템 유사도) 분석**: **추천의 근거**를 보여주는 히트맵. Y축(사용자가 들은 곡)과 X축(추천된 곡) 사이의 **유사도(밝은 사각형)**를 보여줍니다. 예를 들어 'He Doesn't Know Why'와 'Your Protector' 간의 높은 유사도가 추천의 근거가 되었음을 알 수 있습니다. |
| **(23) 모델기반\_특이값크기그래프.png** | **(모델 3: SVD) 분석 1**: SVD(특이값 분해)의 50개 잠재 요인(Latent Factor)별 중요도(Singular Value)를 나타냅니다. 요인 번호가 클수록(오른쪽) 중요도가 급격히 높아지는 것은, 주요 분산이 뒤쪽 요인들에 집중되어 있음을 시사합니다. |
| **(24) 모델기반\_누적설명분산그래프.png** | **(모델 3: SVD) 분석 2**: (23)번을 누적으로 본 그래프. 50개의 잠재 요인으로 데이터 분산의 90% 이상을 설명할 수 있음을 보여줍니다. K=50은 모델의 복잡성과 설명력 사이의 적절한 타협점임을 알 수 있습니다. |
| **(25) 모델기반\_사용자latentscatter.png** | **(모델 3: SVD) 분석 3**: SVD로 추출한 '사용자 잠재 요인'을 2D로 시각화한 것입니다. 각 점이 사용자이며, **사용자의 취향 분포**가 0점 근처에 밀집되어 있음을 보여줍니다. |
| **(26) 모델기반\_아이템latentscatter.png** | **(모델 3: SVD) 분석 4**: '아이템(노래) 잠재 요인'을 2D로 시각화한 것입니다. 각 점이 노래이며, **노래의 특징 분포** 역시 중앙에 밀집되어 있습니다. |
| **(27) 모델기반\_사용자50명과latent간히트맵.png** | **(모델 3: SVD) 분석 5**: 50명(Y축)과 50개 잠재 요인(X축) 간의 관계 히트맵. **특정 사용자(예: 14번)가 특정 요인(예: 18번)에 강한 선호**를 보임을 분석할 수 있어, 잠재 요인이 사용자의 취향을 구분하고 있음을 보여줍니다. |
| **(28) 모델기반\_test유저3명추천.jpg** | **(모델 3: SVD) 결과**: SVD 모델을 통해 **테스트 사용자 3명(id 4, 5, 6)에게 개인화된 추천 목록**을 생성한 텍스트 결과입니다. (예: 5번 사용자는 Justin Bieber를 추천받음). 이는 SVD가 사용자별 취향을 성공적으로 학습했음을 보여줍니다. |
| **(29) 모델기반\_KNN과SVD++결과.png** | **(모델 4, 5: 최종 비교) 결과표**: **이 스크립트의 핵심 결론.** 인기도(Baseline), KNN, SVD++ 모델의 성능을 비교합니다. **SVD++가 RMSE/MAE(오류)는 가장 낮고**, **Precision/Recall/NDCG(정확도)는 가장 높음**을 보여주며, SVD++의 우수성을 입증합니다. |
| **(30) 모델기반\_(29)의막대그래프.png** | **(모델 4, 5: 최종 비교) 시각화**: (29)번 표의 오류 지표(RMSE, MAE)를 막대그래프로 시각화한 것입니다. **SVD++ 모델의 막대가 가장 낮아(오류가 적음) 성능이 가장 우수함**을 한눈에 보여줍니다. |
| **(31) 모델기반\_실제테스트데이터들의청취분포.png** | **(모델 4, 5: 데이터 분석)** `surprise` 모델 학습에 사용된 **실제 테스트 데이터**의 평점(로그 변환된 청취 수) 분포입니다. 대부분의 평점이 1.0~1.5에 몰려있으며, 이는 사용자들이 대부분의 노래를 '가볍게' 청취했음을 의미합니다. |
| **(32) 모델기반\_KNN과SVD++의분포비교.png** | **(모델 4, 5: 예측 비교)** 실제 평점 분포(검은 점선)와 KNN(파란선), SVD++(녹색선) 모델의 **예측값 분포**를 비교한 그래프입니다. SVD++ 모델(녹색선)이 실제 분포의 모양을 더 정확하게 모방하고 있음을 보여줍니다. |
| **(33) 모델기반\_KNN그리드서치.png** | **(모델 4: 하이퍼파라미터 튜닝)** KNN 모델의 최적의 이웃 수(K)를 찾기 위한 그래프입니다. K가 증가함에 따라 RMSE(오류)가 감소하다가 50 근처에서 안정화되며, K=50이 최적의 값(성능과 속도의 균형점)임을 보여줍니다. |
| **(34) 모델기반\_SVD++그리드서치.png** | **(모델 5: 하이퍼파라미터 튜닝)** SVD++ 모델의 최적의 잠재 요인 수(Factor)를 찾기 위한 그래프입니다. 요인 수가 40~50개를 넘어가면서 오류 감소 폭이 둔화되며, 100개에서 최상의 성능을 기록했음을 보여줍니다. |
| **(35) 모델기반\_KNN과SVD++의RMSE분포비교.png** | **(모델 4, 5: 오류 분포 비교)** 두 모델의 예측 오류(절대 오차) 분포입니다. SVD++(녹색)의 분포가 KNN(파란색)보다 0에 더 가깝게 뾰족하며, 이는 SVD++이 **더 많은 예측을 더 정확하게(오류 0에 가깝게) 수행**했음을 의미합니다. |
| **(36) 실제대회였으면3등이었음.png** | **(결론)** 근데, 아무리 그래도 Precision이 겨우 0.17~18밖에 안나와서 뭔가 이상해서 예전 (무려 10년보다 더 된) Kaggle Challenge의 사람들의 실제 점수를 파악했더니 우리의 성능이 꽤나 좋은 편이었던 겁니다! 이 데이터셋의 원본 대회인 "Million Song Dataset Challenge"의 실제 리더보드(순위표)입니다. 이 스크립트의 SVD++ 모델이 기록한 점수(average macro precision)는 **실제 대회에서 3위를 차지할 수 있는 매우 높은 수준**임을 보여주는, 강력한 외부 검증 자료입니다. |
